<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
  <head>
    <title>RLevelUp08_TextMining</title>
    <meta charset="utf-8" />
    <meta name="author" content="LimDongJo" />
    <link href="libs/remark-css/default.css" rel="stylesheet" />
  </head>
  <body>
    <textarea id="source">






---
### 라이브러리 준비
1. rJava, memoise, KoNLP
2. KoNLP 사용을 위해서는 JDK 사전 설치 필요
3. 설치 후, search()를 통해 불러온 것을 확인
4. 설치가 되어 있지 않을 경우, install.packages()를 통해 설치 진행.

```r
library(rJava)
library(memoise)
library(KoNLP)
```

---
### 사전 설정하기
* 기존 형태소 사전의 부족한 단어 수를 보완한 새로운 형태소 사전(NIADic)를 개발하여 제공.

```r
useNIADic()
```
[NiaDic]:https://kbig.kr/portal/kbig/datacube/niadict.page


---
### 사전 설정하기
* 기존 형태소 사전의 부족한 단어 수를 보완한 새로운 형태소 사전(NIADic)를 개발하여 제공.

```r
useNIADic()
```

---
### 텍스트 준비
* 여러줄 문자열 입력
* 강철 도시의 본문중 일부

```r
txt &lt;- '
강철도시
일라이저 베일리는 자기 책상 앞까지 와서야 비로소 사미가 서 있는 것을 알았다. 
"무슨 용건인가?"
"베일리는 언짢은 얼굴을 하고 퉁명스럽게 물었다.
국장님이 부르십니다 베일리 형사님, 급한 일입니다."
알았네.
그러나 사미는 무표정하게 버티고 서 있었다.
'
```

---
### 특수 문자 제거
* 문자열 처리 패키지 불러오기(stringr)
* 특수 문자 제거

```r
library(stringr)
txt &lt;- str_replace_all(txt, "\\W", " ")
txt
```

---
### 명사 추출 및 단어별 빈도 확인
* extractNoun(txt) 명사 추출 함수(KoNLP패키지) 
* unlist() : 만약 벡터가 아닌 리스트 형태라면 1차원 형태로 만든다. 
* table(벡터) : 단어별 빈도를 확인

```r
library(KoNLP)
nouns &lt;- extractNoun(txt)
nouns
```

```
##  [1] "강철"     "도시"     "일라이저" "베일리"   "자기"     "책상"    
##  [7] "앞"       "사미"     "것"       "용건"     "베일리"   "얼굴"    
## [13] "퉁명"     "국장님"   "베일리"   "형사"     "님"       "일"      
## [19] "사미"     "무표정"   "하게"     "있었"
```

```r
wordCount &lt;- table(unlist(nouns))
wordCount
```

```
## 
##     강철       것   국장님       님     도시   무표정   베일리     사미 
##        1        1        1        1        1        1        3        2 
##       앞     얼굴     용건       일 일라이저     있었     자기     책상 
##        1        1        1        1        1        1        1        1 
##     퉁명     하게     형사 
##        1        1        1
```


---
### 실습 해보기 1-1
* (1) barplot를 이용하여 단어별 빈도를 막대그래프로 그려보자.  
* (2) ggplot를 활용하여 단어별 빈도를 확인해 보자.
  * (Hint) ggplot은 데이터 프레임을 활용해 본다. 
* (LevelUp) 자신만의 텍스트 문서를 만들어 이를 불러와 빈도 분석을 수행해 본다. (파일 읽기 시, readLines 이용)

---
### 워드 클라우드
1. 텍스트에서 빈번히 사용된 키워드를 시각적으로 표시.
2. 사용빈도가 높은 단어일수록 큰 글씨로 표시 가능.
3. 필요 패키지 (wordcloud)


```r
install.packages("wordcloud")
library(wordcloud)
```

---
### 01 텍스트 준비
* 강철도시 - 본문 사용

```r
txt &lt;- '
강철도시
일라이저 베일리는 자기 책상 앞까지 와서야 비로소 사미가 서 있는 것을 알았다. 
"무슨 용건인가?"
"베일리는 언짢은 얼굴을 하고 퉁명스럽게 물었다.
국장님이 부르십니다 베일리 형사님, 급한 일입니다."
알았네.
그러나 사미는 무표정하게 버티고 서 있었다.
'
```


---
### 02 사전 불러오기 및 명사 추출
* 강철도시 - 본문 사용

```r
#### 02 세종 사전 불러오기
useSejongDic()
```

```
## Backup was just finished!
## 370957 words dictionary was built.
```

```r
#### 03 명사 추출
nouns &lt;- extractNoun(txt)
nouns
```

```
##  [1] "강철"     "도시"     "일라이저" "베일리"   "자기"     "책상"    
##  [7] "앞"       "사미"     "것"       "용건"     "베일리"   "얼굴"    
## [13] "퉁명"     "국장님"   "베일리"   "형사"     "님"       "일"      
## [19] "사미"     "무표정"   "하게"
```

---
### 03 명사중, 2글자 이상인 것만 가져오기

```r
word &lt;- unlist(nouns)  # 1차원 배열로 만들기
word
```

```
##  [1] "강철"     "도시"     "일라이저" "베일리"   "자기"     "책상"    
##  [7] "앞"       "사미"     "것"       "용건"     "베일리"   "얼굴"    
## [13] "퉁명"     "국장님"   "베일리"   "형사"     "님"       "일"      
## [19] "사미"     "무표정"   "하게"
```

```r
word &lt;- word[nchar(word)&gt;= 2]
word
```

```
##  [1] "강철"     "도시"     "일라이저" "베일리"   "자기"     "책상"    
##  [7] "사미"     "용건"     "베일리"   "얼굴"     "퉁명"     "국장님"  
## [13] "베일리"   "형사"     "사미"     "무표정"   "하게"
```

---
### 04 단어 빈도 확인

```r
#### 단어 빈도 확인
wordFreq &lt;- table(word)
wordFreq
```

```
## word
##     강철   국장님     도시   무표정   베일리     사미     얼굴     용건 
##        1        1        1        1        3        2        1        1 
## 일라이저     자기     책상     퉁명     하게     형사 
##        1        1        1        1        1        1
```

---
### 05 색 지정
* 패키지 : install.packages("RColorBrewer")

```r
library(RColorBrewer)
pal &lt;- brewer.pal(6, "Dark2")
pal
```

```
## [1] "#1B9E77" "#D95F02" "#7570B3" "#E7298A" "#66A61E" "#E6AB02"
```

---
### 06 워드 클라우드 시각화

```r
library(wordcloud)
windowsFonts(malgun=windowsFont("맑은 고딕"))
set.seed(1000)
wordcloud(word=names(wordFreq),
          freq=wordFreq,
          colors=pal,
          min.freq=1,
          random.order=F,
          family="malgun")
```

![](RLevelUp08_TextMining_files/figure-html/unnamed-chunk-13-1.png)&lt;!-- --&gt;
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false,
"ratio": "4:3"
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();</script>

<script>
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
